import sounddevice as sd
import scipy.io.wavfile as wav
import os
from faster_whisper import WhisperModel
import numpy as np
import time
from mic_settings import save_mic_index, load_mic_index

def select_input_device():
    import sounddevice as sd
    devices = sd.query_devices()
    # Windowsì˜ ë§ˆì´í¬ ì„¤ì • ì°½ê³¼ ìœ ì‚¬í•˜ê²Œ, hostapiê°€ WASAPI/DirectSound/Windows MME ë“±ì¸ ì…ë ¥ ì¥ì¹˜ë§Œ í‘œì‹œ
    hostapi_names = [sd.query_hostapis()[i]['name'] for i in range(len(sd.query_hostapis()))]
    input_devices = []
    for i, d in enumerate(devices):
        if d['max_input_channels'] > 0 and d['name'].strip() and d['default_samplerate'] > 0:
            hostapi = hostapi_names[d['hostapi']] if d['hostapi'] < len(hostapi_names) else 'Unknown'
            input_devices.append((i, d, hostapi))
    print("[ì‚¬ìš© ê°€ëŠ¥í•œ ë§ˆì´í¬ ëª©ë¡]")
    for idx, (i, d, hostapi) in enumerate(input_devices, 1):
        print(f"{idx}. {d['name']} (id={i}, {hostapi})")
    if not input_devices:
        print("â— ì…ë ¥ ê°€ëŠ¥í•œ ë§ˆì´í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    while True:
        try:
            sel = int(input(f"ì‚¬ìš©í•  ë§ˆì´í¬ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1~{len(input_devices)}): "))
            if 1 <= sel <= len(input_devices):
                device_index = input_devices[sel-1][0]
                save_mic_index(device_index)
                return device_index
        except Exception:
            pass
        print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•˜ì„¸ìš”.")

def record_voice(duration=5, fs=44100, device_name="erpon", device_index=None):
    print("ğŸ¤ ë§í•˜ì„¸ìš”...")
    if device_index is None:
        device_index = None
        for idx, dev in enumerate(sd.query_devices()):
            if device_name.lower() in dev['name'].lower() and dev['max_input_channels'] > 0:
                device_index = idx
                break
    if device_index is None:
        print(f"â— '{device_name}' ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        device_index = None
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, device=device_index)
    sd.wait()
    print("ğŸ›‘ ë…¹ìŒì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    return audio, fs

def record_voice_until_silence(fs=44100, device_name="erpon", silence_sec=3, silence_threshold=0.01, max_duration=60, device_index=None):
    if device_index is None:
        device_index = None
        for idx, dev in enumerate(sd.query_devices()):
            if device_name.lower() in dev['name'].lower() and dev['max_input_channels'] > 0:
                device_index = idx
                break
    print(f"ğŸ¤ ë§í•˜ì„¸ìš”... ({silence_sec}ì´ˆ ì´ìƒ ì¡°ìš©í•˜ë©´ ìë™ ì¢…ë£Œ)")
    if device_index is None:
        print(f"â— '{device_name}' ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        device_index = None

    buffer = []
    last_sound = time.time()
    start_time = time.time()

    def callback(indata, frames, time_info, status):
        nonlocal last_sound
        buffer.append(indata.copy())
        if np.abs(indata).max() > silence_threshold:
            last_sound = time.time()

    with sd.InputStream(samplerate=fs, channels=1, device=device_index, callback=callback):
        while True:
            sd.sleep(200)
            if time.time() - last_sound > silence_sec:
                print(f"ğŸ›‘ {silence_sec}ì´ˆ ì´ìƒ ì¡°ìš©í•˜ì—¬ ë…¹ìŒì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            if time.time() - start_time > max_duration:
                print("â° ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ì´ˆê³¼ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

    audio = np.concatenate(buffer, axis=0)
    return audio, fs

def save_temp_wav(audio, fs, silence_threshold=0):
    save_dir = os.path.join(os.getcwd(), "deta")
    os.makedirs(save_dir, exist_ok=True)
    file_count = len([f for f in os.listdir(save_dir) if f.endswith('.wav')])
    file_path = os.path.join(save_dir, f"recorded_{file_count+1}.wav")
    if abs(audio).max() < silence_threshold:
        print("â— ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì‘ì•„ì„œ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    wav.write(file_path, fs, audio)
    return file_path

def transcribe(audio_path):
    model = WhisperModel("medium", device="cpu", compute_type="int8")
    segments, _ = model.transcribe(audio_path, language="en")
    return " ".join([seg.text for seg in segments])

def wait_for_voice(fs=44100, device_index=None, threshold=0.01, max_wait=60):
    """
    ë§ˆì´í¬ì—ì„œ ì†Œë¦¬ê°€ ê°ì§€ë  ë•Œê¹Œì§€ ëŒ€ê¸°, ê°ì§€ë˜ë©´ True ë°˜í™˜
    """
    import time
    import numpy as np
    print("ğŸ¤ ë…¹ìŒ ëŒ€ê¸° ì¤‘... (ë§ˆì´í¬ì— ì†Œë¦¬ê°€ ê°ì§€ë˜ë©´ ìë™ ë…¹ìŒ ì‹œì‘)")
    start_time = time.time()
    detected = False
    def callback(indata, frames, time_info, status):
        nonlocal detected
        if np.abs(indata).max() > threshold:
            detected = True
    with sd.InputStream(samplerate=fs, channels=1, device=device_index, callback=callback):
        while not detected:
            sd.sleep(100)
            if time.time() - start_time > max_wait:
                print("â° ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                return False
    print("ğŸ”Š ì†Œë¦¬ ê°ì§€! ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    return True
