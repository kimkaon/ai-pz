import sounddevice as sd
import scipy.io.wavfile as wav
import os
from faster_whisper import WhisperModel
import numpy as np
import time

# í†µí•© ì„¤ì • ê´€ë¦¬ì ì„í¬íŠ¸
try:
    from settings_manager import get_settings_manager
    settings_manager = get_settings_manager()
    
    def save_mic_index(device_index):
        """ë§ˆì´í¬ ì¸ë±ìŠ¤ ì €ì¥ (í˜¸í™˜ì„± ìœ ì§€)"""
        settings_manager.set_microphone_device(device_index)
    
    def load_mic_index():
        """ë§ˆì´í¬ ì¸ë±ìŠ¤ ë¡œë“œ (í˜¸í™˜ì„± ìœ ì§€)"""
        return settings_manager.get('microphone.device_index')
    
    def log_print(message, log_type="general"):
        """ë¡œê·¸ ì¶œë ¥ (í˜¸í™˜ì„± ìœ ì§€)"""
        if settings_manager.should_show_log(log_type):
            print(message)
            
except ImportError:
    # í´ë°±: ê¸°ë³¸ í•¨ìˆ˜ë“¤
    def save_mic_index(device_index):
        print(f"ë§ˆì´í¬ ì¸ë±ìŠ¤ ì €ì¥: {device_index}")
    
    def load_mic_index():
        return None
    
    def log_print(message, log_type="general"):
        print(message)

def select_input_device():
    import sounddevice as sd
    devices = sd.query_devices()
    # Windowsì˜ ë§ˆì´í¬ ì„¤ì • ì°½ê³¼ ìœ ì‚¬í•˜ê²Œ, hostapiê°€ WASAPI/DirectSound/Windows MME ë“±ì¸ ì…ë ¥ ì¥ì¹˜ë§Œ í‘œì‹œ
    hostapi_names = [sd.query_hostapis()[i]['name'] for i in range(len(sd.query_hostapis()))]
    input_devices = []
    for i, d in enumerate(devices):
        if d['max_input_channels'] > 0 and d['name'].strip() and d['default_samplerate'] > 0:
            hostapi = hostapi_names[d['hostapi']] if d['hostapi'] < len(hostapi_names) else 'Unknown'
            input_devices.append((i, d, hostapi))
    print("[ì‚¬ìš© ê°€ëŠ¥í•œ ë§ˆì´í¬ ëª©ë¡]")
    for idx, (i, d, hostapi) in enumerate(input_devices, 1):
        print(f"{idx}. {d['name']} (id={i}, {hostapi})")
    if not input_devices:
        print("â— ì…ë ¥ ê°€ëŠ¥í•œ ë§ˆì´í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    while True:
        try:
            sel = int(input(f"ì‚¬ìš©í•  ë§ˆì´í¬ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1~{len(input_devices)}): "))
            if 1 <= sel <= len(input_devices):
                device_index = input_devices[sel-1][0]
                save_mic_index(device_index)
                return device_index
        except Exception:
            pass
        print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•˜ì„¸ìš”.")

def record_voice(duration=5, fs=44100, device_name="erpon", device_index=None):
    log_print("ğŸ¤ ë§í•˜ì„¸ìš”...", "audio_processing")
    if device_index is None:
        device_index = None
        for idx, dev in enumerate(sd.query_devices()):
            if device_name.lower() in dev['name'].lower() and dev['max_input_channels'] > 0:
                device_index = idx
                break
    if device_index is None:
        print(f"â— '{device_name}' ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        device_index = None
    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, device=device_index)
    sd.wait()
    log_print("ğŸ›‘ ë…¹ìŒì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", "audio_processing")
    return audio, fs

def record_voice_until_silence(fs=44100, device_name="erpon", silence_sec=2, silence_threshold=0.015, max_duration=30, device_index=None):
    """
    ì‹¤ì‹œê°„ ëŒ€í™”ë¥¼ ìœ„í•œ ê°œì„ ëœ ìŒì„± ë…¹ìŒ
    - ë” ì§§ì€ ì¹¨ë¬µ ê°ì§€ ì‹œê°„ (3ì´ˆ -> 2ì´ˆ)
    - ë” ë¯¼ê°í•œ threshold
    - ë” ì§§ì€ ìµœëŒ€ ë…¹ìŒ ì‹œê°„ (60ì´ˆ -> 30ì´ˆ)
    """
    if device_index is None:
        device_index = None
        for idx, dev in enumerate(sd.query_devices()):
            if device_name.lower() in dev['name'].lower() and dev['max_input_channels'] > 0:
                device_index = idx
                break
    
    print(f"ğŸ¤ ë…¹ìŒ ì¤‘... ({silence_sec}ì´ˆ ì¹¨ë¬µ ì‹œ ìë™ ì¢…ë£Œ)")
    if device_index is None:
        log_print(f"â— '{device_name}' ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.", "audio_processing")
        device_index = None

    buffer = []
    last_sound = time.time()
    start_time = time.time()
    sound_detected = False

    def callback(indata, frames, time_info, status):
        nonlocal last_sound, sound_detected
        buffer.append(indata.copy())
        if np.abs(indata).max() > silence_threshold:
            last_sound = time.time()
            sound_detected = True

    with sd.InputStream(samplerate=fs, channels=1, device=device_index, callback=callback):
        while True:
            sd.sleep(100)  # ë” ë¹ ë¥¸ ì²´í¬
            current_time = time.time()
            
            # ì†Œë¦¬ê°€ ê°ì§€ëœ í›„ ì¹¨ë¬µ ì‹œê°„ ì²´í¬
            if sound_detected and (current_time - last_sound > silence_sec):
                log_print(f"ğŸ›‘ {silence_sec}ì´ˆ ì¹¨ë¬µìœ¼ë¡œ ë…¹ìŒ ì¢…ë£Œ", "audio_processing")
                break
                
            # ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ì²´í¬
            if current_time - start_time > max_duration:
                log_print("â° ìµœëŒ€ ë…¹ìŒ ì‹œê°„ ì´ˆê³¼ë¡œ ì¢…ë£Œ", "audio_processing")
                break
                
            # ì†Œë¦¬ ê°ì§€ ì—†ì´ 5ì´ˆê°€ ì§€ë‚˜ë©´ ì¢…ë£Œ
            if not sound_detected and (current_time - start_time > 5):
                log_print("â— ì†Œë¦¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•„ ë…¹ìŒ ì¢…ë£Œ", "audio_processing")
                break

    audio = np.concatenate(buffer, axis=0)
    
    # ë…¹ìŒ í’ˆì§ˆ ì²´í¬
    if len(audio) < fs * 0.5:  # 0.5ì´ˆ ë¯¸ë§Œì´ë©´ ë„ˆë¬´ ì§§ìŒ
        log_print("â— ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤", "audio_processing")
        return audio, fs
    
    log_print(f"âœ… ë…¹ìŒ ì™„ë£Œ ({len(audio)/fs:.1f}ì´ˆ)", "audio_processing")
    return audio, fs

def save_temp_wav(audio, fs, silence_threshold=0):
    save_dir = os.path.join(os.getcwd(), "deta")
    os.makedirs(save_dir, exist_ok=True)
    file_count = len([f for f in os.listdir(save_dir) if f.endswith('.wav')])
    file_path = os.path.join(save_dir, f"recorded_{file_count+1}.wav")
    if abs(audio).max() < silence_threshold:
        print("â— ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì‘ì•„ì„œ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    wav.write(file_path, fs, audio)
    return file_path

def transcribe(audio_path):
    # GPU ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ smaller ëª¨ë¸ ì‚¬ìš© (medium â†’ base)
    # LLMì´ ì´ë¯¸ GPU ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë¯€ë¡œ CPU ëª¨ë¸ ìš°ì„  ì‹œë„
    try:
        # CPU ëª¨ë¸ë¡œ ë¨¼ì € ì‹œë„ (GPU ë©”ëª¨ë¦¬ ì ˆì•½)
        model = WhisperModel("base", device="cpu", compute_type="int8")
        log_print("[Whisper] CPU ëª¨ë¸ ì‚¬ìš© (GPU ë©”ëª¨ë¦¬ ì ˆì•½)", "model_loading")
    except Exception as e:
        log_print(f"[Whisper] CPU ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}", "model_loading")
        # ìµœí›„ ìˆ˜ë‹¨ìœ¼ë¡œ GPU ì‹œë„
        try:
            model = WhisperModel("base", device="cuda", compute_type="float16")
            log_print("[Whisper] GPU ëª¨ë¸ ì‚¬ìš©", "model_loading")
        except Exception as e2:
            log_print(f"[Whisper] GPU ëª¨ë¸ë„ ì‹¤íŒ¨: {e2}", "model_loading")
            raise Exception("Whisper ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

    segments, _ = model.transcribe(audio_path, language="en")
    return " ".join([seg.text for seg in segments])


def wait_for_voice(fs=44100, device_index=None, threshold=0.015, max_wait=300):
    """
    ë§ˆì´í¬ì—ì„œ ì†Œë¦¬ê°€ ê°ì§€ë  ë•Œê¹Œì§€ ëŒ€ê¸°, ê°ì§€ë˜ë©´ True ë°˜í™˜
    ì‹¤ì‹œê°„ ëŒ€í™”ë¥¼ ìœ„í•´ ë” ë¯¼ê°í•˜ê³  ë¹ ë¥¸ ê°ì§€
    """
    import time
    import numpy as np
    log_print("ğŸ¤ ëŒ€ê¸° ì¤‘... (ë§ì”€í•˜ì„¸ìš”)", "audio_processing")
    start_time = time.time()
    detected = False
    
    def callback(indata, frames, time_info, status):
        nonlocal detected
        # ë” ë¯¼ê°í•œ ê°ì§€ë¥¼ ìœ„í•´ threshold ì¡°ì •
        if np.abs(indata).max() > threshold:
            detected = True
    
    with sd.InputStream(samplerate=fs, channels=1, device=device_index, callback=callback):
        while not detected:
            sd.sleep(50)  # ë” ë¹ ë¥¸ ì²´í¬ (100ms -> 50ms)
            if time.time() - start_time > max_wait:
                print("â° ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼. ë©”ë‰´ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.")
                return False
    
    log_print("ğŸ”Š ìŒì„± ê°ì§€! ë…¹ìŒ ì‹œì‘", "audio_processing")
    return True
