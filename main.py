import torch
import numpy as np
import warnings
import os

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore")
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # TensorFlow ë¡œê·¸ ìˆ¨ê¸°ê¸°
os.environ['PYTORCH_WARNINGS'] = '0'  # PyTorch ê²½ê³  ìˆ¨ê¸°ê¸°

print("main.pyì—ì„œ GPU ì´ë¦„:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "N/A")

from config_gpu import setup_gpu
setup_gpu(cuda_device=0)
from voice_utils import record_voice, save_temp_wav, transcribe, select_input_device, record_voice_until_silence
from nous_hermes2_mistral_loader import load_nous_hermes2_mistral, chat_nous_hermes2_mistral
from mic_settings import save_mic_index, load_mic_index
from prompt_templates import make_role_prompt
from openvoice_tts import synthesize_with_openvoice
from log_settings import toggle_verbose_mode, is_verbose_mode, log_print, get_current_settings
import sounddevice as sd
import soundfile as sf
import re

def clean_llm_response(response):
    """
    LLM ì‘ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì„ ì œê±°í•˜ì—¬ TTSì— ì í•©í•œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
    """
    if not response:
        return ""
    
    # ì—¬ëŸ¬ ê°€ì§€ íŒ¨í„´ìœ¼ë¡œ ì •ë¦¬
    cleaned = response.strip()
    
    # ì—¬ëŸ¬ ì¤„ì— ê±¸ì¹œ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¤„ë³„ë¡œ ë¶„ë¦¬
    lines = cleaned.split('\n')
    filtered_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Type:, Classification:, Category: íŒ¨í„´ ì œê±°
        if re.match(r'^(Type|Classification|Category)\s*:', line, flags=re.IGNORECASE):
            continue
            
        # ëŒ€ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë¶„ë¥˜ë§Œ ìˆëŠ” ì¤„ ì œê±°
        if re.match(r'^\[.*?\]$', line):
            continue
            
        # ë¶„ë¥˜ëª…ë§Œ ìˆëŠ” ì¤„ ì œê±°
        if line.lower() in ['qna', 'daily chat', 'specific program', 'unknown']:
            continue
        
        # Answer:, QnA: ë“±ì˜ ì ‘ë‘ì‚¬ ì œê±°
        line = re.sub(r'^(answer|qna|daily chat|specific program|unknown)\s*:\s*', '', line, flags=re.IGNORECASE)
        
        # ëŒ€ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë¶„ë¥˜ ì •ë³´ ì œê±°
        line = re.sub(r'^\[.*?\]\s*', '', line)
        
        if line:  # ë¹ˆ ì¤„ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
            filtered_lines.append(line)
    
    # ì¤„ë“¤ì„ ê³µë°±ìœ¼ë¡œ ì—°ê²°
    cleaned = ' '.join(filtered_lines)
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    cleaned = re.sub(r'\s+', ' ', cleaned)
    
    # ì–‘ìª½ ê³µë°± ì œê±°
    cleaned = cleaned.strip()
    
    # ë¹ˆ ë¬¸ìì—´ì´ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
    if not cleaned:
        return "Sorry, I couldn't generate a proper response."
    
    return cleaned

def main():
    llm = load_nous_hermes2_mistral()

    # ë§ˆì´í¬ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ë˜ëŠ” ì¬ì„¤ì •
    device_index = load_mic_index()

    # ì…ë ¥ ë°©ì‹ ì„ íƒ (ì˜ëª»ëœ ì…ë ¥ ì‹œ ë°˜ë³µ)
    while True:
        current_verbose = "ON" if is_verbose_mode() else "OFF"
        mode = input(f"ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (s: ìŒì„±, m: ë©”ì‹œì§€, p: ë§ˆì´í¬ ì¬ì„¤ì •, lg: ë¡œê·¸ ëª¨ë“œ [{current_verbose}]): ").strip().lower()
        if mode in ["s", "m", "p", "lg"]:
            break
        print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”. (s: ìŒì„±, m: ë©”ì‹œì§€, p: ë§ˆì´í¬ ì¬ì„¤ì •, lg: ë¡œê·¸ ëª¨ë“œ)")

    if mode == "lg":
        settings = toggle_verbose_mode()
        new_verbose = "ON" if settings["verbose_mode"] else "OFF"
        print(f"âœ… ë¡œê·¸ ëª¨ë“œê°€ [{new_verbose}]ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        log_print(f"ë¡œê·¸ ì„¤ì •: {settings}", "general")
        # ë¡œê·¸ ëª¨ë“œ ë³€ê²½ í›„ ë‹¤ì‹œ ì…ë ¥ ë°©ì‹ ì„ íƒ
        while True:
            mode = input("ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (s: ìŒì„±, m: ë©”ì‹œì§€, p: ë§ˆì´í¬ ì¬ì„¤ì •): ").strip().lower()
            if mode in ["s", "m", "p"]:
                break
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”. (s: ìŒì„±, m: ë©”ì‹œì§€, p: ë§ˆì´í¬ ì¬ì„¤ì •)")

    if mode == "p":
        device_index = select_input_device()
        print(f"ì„ íƒëœ ë§ˆì´í¬ index: {device_index}")
        # ë§ˆì´í¬ ì¬ì„¤ì • í›„ ë‹¤ì‹œ ì…ë ¥ ë°©ì‹ ì„ íƒ
        while True:
            mode = input("ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (s: ìŒì„±, m: ë©”ì‹œì§€): ").strip().lower()
            if mode in ["s", "m"]:
                break
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”. (s: ìŒì„±, m: ë©”ì‹œì§€)")

    while True:
        if mode == "s":
            from voice_utils import wait_for_voice
            # ë…¹ìŒ ëŒ€ê¸° ëª¨ë“œ: ì†Œë¦¬ ê°ì§€ë  ë•Œê¹Œì§€ ëŒ€ê¸°
            if not wait_for_voice(device_index=device_index):
                continue
            audio, fs = record_voice_until_silence(device_index=device_index)
            # ìŒì„± ì…ë ¥ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ì¬ë…¹ìŒ(ëŒ€ê¸°ëª¨ë“œë¡œ ë³µê·€, íŒŒì¼ ì €ì¥ X)
            if np.abs(audio).max() < 0.01:
                print("â— ìŒì„± ì¸ì‹ì´ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë…¹ìŒ ëŒ€ê¸°ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                continue
            # ìŒì„± ì‹ í˜¸ê°€ ì¶©ë¶„í•  ë•Œë§Œ íŒŒì¼ ì €ì¥
            wav_path = save_temp_wav(audio, fs, silence_threshold=0.01)
            if wav_path is None:
                print("â— ìŒì„± ì¸ì‹ì´ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë…¹ìŒ ëŒ€ê¸°ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                continue
            print(f"ì €ì¥ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ: {wav_path}")
            prompt = transcribe(wav_path)
            print(f"ğŸ—£ ì¸ì‹ëœ ë§: {prompt}")
            if not prompt.strip():
                print("â— ìŒì„± ì¸ì‹ì´ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë…¹ìŒ ëŒ€ê¸°ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                continue
        else:
            # ë©”ì‹œì§€ ì…ë ¥ ëª¨ë“œ
            prompt = input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if not prompt:
                print("â— ì•„ë¬´ ë©”ì‹œì§€ë„ ì…ë ¥ë˜ì§€ ì•Šì•˜ì–´ìš”.")
                continue

        if not prompt:
            print("â— ì•„ë¬´ ë§ë„ ì¸ì‹ë˜ì§€ ì•Šì•˜ì–´ìš”.")
            continue

        # ì¢…ë£Œ ëª…ë ¹ì–´ ì²˜ë¦¬
        if any(x in prompt.lower() for x in ["over", "it's over"]):
            print("ğŸ›‘ 'over'ê°€ ê°ì§€ë˜ì–´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # Nous Hermes 2 - Mistral ì‘ë‹µ ìƒì„±
        prompt_for_llm = make_role_prompt(prompt)
        raw_response = chat_nous_hermes2_mistral(llm, prompt_for_llm)
        
        # ì‘ë‹µ ì •ë¦¬ (TTSìš©)
        response = clean_llm_response(raw_response)
        
        # ë¡œê·¸ ëª¨ë“œì— ë”°ë¥¸ ì¶œë ¥ ë¶„ê¸°
        if is_verbose_mode():
            print(f"ğŸ¤– Nous Hermes 2 - Mistralì˜ ì›ë³¸ ì‘ë‹µ:\n{raw_response}\n")
            log_print(f"ğŸ™ï¸ TTSìš© ì •ë¦¬ëœ ì‘ë‹µ: {response}", "tts_debug")
        else:
            print(f"ğŸ¤– {response}")  # ë¡œê·¸ OFFì¼ ë•ŒëŠ” ì •ë¦¬ëœ ì‘ë‹µë§Œ í‘œì‹œ

        # OpenVoice TTSë¡œ ì‘ë‹µì„ ìŒì„±(wav)ìœ¼ë¡œ í•©ì„± ë° ì¬ìƒ
        tts_output_dir = "tts_output"
        if not os.path.exists(tts_output_dir):
            os.makedirs(tts_output_dir)
        
        tts_wav_path = os.path.join(tts_output_dir, "response.wav")
        try:
            # ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
            import warnings
            warnings.filterwarnings("ignore")
            
            synthesize_with_openvoice(response, tts_wav_path, language="English", verbose=is_verbose_mode())
            
            # ìƒì„±ëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if os.path.exists(tts_wav_path) and os.path.getsize(tts_wav_path) > 0:
                data, fs = sf.read(tts_wav_path, dtype='float32')
                log_print("ğŸ”Š TTS ìŒì„± ì¬ìƒ ì¤‘...", "tts_status")
                sd.play(data, fs)
                sd.wait()
                log_print("âœ… TTS ìŒì„± ì¬ìƒ ì™„ë£Œ", "tts_status")
            else:
                print("âŒ TTS íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        except NotImplementedError:
            print("[TTS] OpenVoice TTS í•©ì„± í•¨ìˆ˜ê°€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"[TTS] ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

if __name__ == "__main__":
    main()
# This code is a simple voice interaction system that records audio, transcribes it using Whisper, and generates a response using Nous Hermes 2 - Mistral GGUF.
# It uses sounddevice for audio recording, scipy for saving audio files, and faster_whisper for transcription.
# The Llama model is loaded using llama-cpp-python, and the chat function generates responses based on the GGUF model.