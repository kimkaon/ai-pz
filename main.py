import torch
import numpy as np
print("main.pyì—ì„œ GPU ì´ë¦„:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "N/A")

from config_gpu import setup_gpu
setup_gpu(cuda_device=0)
from voice_utils import record_voice, save_temp_wav, transcribe, select_input_device, record_voice_until_silence
from nous_hermes2_mistral_loader import load_nous_hermes2_mistral, chat_nous_hermes2_mistral
from mic_settings import save_mic_index, load_mic_index
from prompt_templates import make_role_prompt
from openvoice_tts import synthesize_with_openvoice
import sounddevice as sd
import soundfile as sf

def main():
    llm = load_nous_hermes2_mistral()

    # ë§ˆì´í¬ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ë˜ëŠ” ì¬ì„¤ì •
    device_index = load_mic_index()

    # ì…ë ¥ ë°©ì‹ ì„ íƒ (ì˜ëª»ëœ ì…ë ¥ ì‹œ ë°˜ë³µ)
    while True:
        mode = input("ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (s: ìŒì„±, m: ë©”ì‹œì§€, p: ë§ˆì´í¬ ì¬ì„¤ì •): ").strip().lower()
        if mode in ["s", "m", "p"]:
            break
        print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”. (s: ìŒì„±, m: ë©”ì‹œì§€, p: ë§ˆì´í¬ ì¬ì„¤ì •)")

    if mode == "p":
        device_index = select_input_device()
        print(f"ì„ íƒëœ ë§ˆì´í¬ index: {device_index}")
        # ë§ˆì´í¬ ì¬ì„¤ì • í›„ ë‹¤ì‹œ ì…ë ¥ ë°©ì‹ ì„ íƒ
        while True:
            mode = input("ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (s: ìŒì„±, m: ë©”ì‹œì§€): ").strip().lower()
            if mode in ["s", "m"]:
                break
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”. (s: ìŒì„±, m: ë©”ì‹œì§€)")

    while True:
        if mode == "s":
            from voice_utils import wait_for_voice
            # ë…¹ìŒ ëŒ€ê¸° ëª¨ë“œ: ì†Œë¦¬ ê°ì§€ë  ë•Œê¹Œì§€ ëŒ€ê¸°
            if not wait_for_voice(device_index=device_index):
                continue
            audio, fs = record_voice_until_silence(device_index=device_index)
            # ìŒì„± ì…ë ¥ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ì¬ë…¹ìŒ(ëŒ€ê¸°ëª¨ë“œë¡œ ë³µê·€, íŒŒì¼ ì €ì¥ X)
            if np.abs(audio).max() < 0.01:
                print("â— ìŒì„± ì¸ì‹ì´ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë…¹ìŒ ëŒ€ê¸°ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                continue
            # ìŒì„± ì‹ í˜¸ê°€ ì¶©ë¶„í•  ë•Œë§Œ íŒŒì¼ ì €ì¥
            wav_path = save_temp_wav(audio, fs, silence_threshold=0.01)
            if wav_path is None:
                print("â— ìŒì„± ì¸ì‹ì´ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë…¹ìŒ ëŒ€ê¸°ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                continue
            print(f"ì €ì¥ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ: {wav_path}")
            prompt = transcribe(wav_path)
            print(f"ğŸ—£ ì¸ì‹ëœ ë§: {prompt}")
            if not prompt.strip():
                print("â— ìŒì„± ì¸ì‹ì´ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë…¹ìŒ ëŒ€ê¸°ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                continue
        else:
            # ë©”ì‹œì§€ ì…ë ¥ ëª¨ë“œ
            prompt = input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if not prompt:
                print("â— ì•„ë¬´ ë©”ì‹œì§€ë„ ì…ë ¥ë˜ì§€ ì•Šì•˜ì–´ìš”.")
                continue

        if not prompt:
            print("â— ì•„ë¬´ ë§ë„ ì¸ì‹ë˜ì§€ ì•Šì•˜ì–´ìš”.")
            continue

        # ì¢…ë£Œ ëª…ë ¹ì–´ ì²˜ë¦¬
        if any(x in prompt.lower() for x in ["over", "it's over"]):
            print("ğŸ›‘ 'over'ê°€ ê°ì§€ë˜ì–´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # Nous Hermes 2 - Mistral ì‘ë‹µ ìƒì„±
        prompt_for_llm = make_role_prompt(prompt)
        response = chat_nous_hermes2_mistral(llm, prompt_for_llm)
        print(f"ğŸ¤– Nous Hermes 2 - Mistralì˜ ì‘ë‹µ:\n{response}\n")

        # OpenVoice TTSë¡œ ì‘ë‹µì„ ìŒì„±(wav)ìœ¼ë¡œ í•©ì„± ë° ì¬ìƒ
        tts_wav_path = "output_tts.wav"
        try:
            synthesize_with_openvoice(response, tts_wav_path, language="en")
            data, fs = sf.read(tts_wav_path, dtype='float32')
            print("ğŸ”Š TTS ìŒì„± ì¬ìƒ ì¤‘...")
            sd.play(data, fs)
            sd.wait()
        except NotImplementedError:
            print("[TTS] OpenVoice TTS í•©ì„± í•¨ìˆ˜ê°€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"[TTS] ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
# This code is a simple voice interaction system that records audio, transcribes it using Whisper, and generates a response using Nous Hermes 2 - Mistral GGUF.
# It uses sounddevice for audio recording, scipy for saving audio files, and faster_whisper for transcription.
# The Llama model is loaded using llama-cpp-python, and the chat function generates responses based on the GGUF model.